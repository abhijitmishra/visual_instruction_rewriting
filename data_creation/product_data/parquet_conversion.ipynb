{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet Conversion File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary files\n",
    "import pandas as pd\n",
    "import os\n",
    "import base64\n",
    "# import pyarrow \n",
    "# import fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**function to add images to data frame & save as parquet file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def image_to_base64(filepath):\n",
    "    '''Convert image to base64 string'''\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as image_file:\n",
    "            base64_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return base64_string\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {filepath} to base64: {e}\")\n",
    "        return None\n",
    "\n",
    "# main/core function\n",
    "def add_images_to_dataframe(input_tsv, output, image_folder):\n",
    "    '''Function to add images to the DataFrame and save as parquet'''\n",
    "    # read the input as TSV file\n",
    "    df = pd.read_csv(input_tsv, sep='\\t', encoding='ISO-8859-1')\n",
    "    \n",
    "    image_base64_list = []\n",
    "    image_path_list = []\n",
    "    for image_id in df['Image Id']:\n",
    "        image_path = os.path.join(image_folder, f\"{image_id}.jpg\")\n",
    "        image_base64 = image_to_base64(image_path)\n",
    "        if image_base64:\n",
    "            image_base64_list.append(image_base64)\n",
    "            image_path_list.append(f\"{image_id}.jpg\")\n",
    "        else:\n",
    "            # raise error if image is not found\n",
    "            raise Exception(f\"IMG file not found: {image_id}\")\n",
    "    \n",
    "    df['image'] = image_base64_list\n",
    "    df['image_path'] = image_path_list\n",
    "    \n",
    "    columns_to_save = [\"image\", \"image_path\", \"Image Id\", \"Prompt\", \"Rewritten Question\"]\n",
    "    if 'Category' in df.columns:\n",
    "        columns_to_save.append('Category') # include this if needed\n",
    "    df = df[columns_to_save]\n",
    "    \n",
    "    # save the updated DataFrame to a .parquet file\n",
    "    df.to_parquet(output)\n",
    "    print(f\"File: {output} updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize input and output file paths\n",
    "input_tsv = \"C:/Users//ReVision/data/product_data/test_product_data_rewrite.tsv\"\n",
    "valid_output = \"C:/Users//ReVision/data/product_data/test_product_data_rewrite.parquet\"\n",
    "image_folder = \"C:/Users//ReVision/data/product_data/product_images\"\n",
    "\n",
    "add_images_to_dataframe(input_tsv, valid_output, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tsv = \"C:/Users//ReVision/data/product_data/train_product_data_rewrite.tsv\"\n",
    "valid_output = \"C:/Users//ReVision/data/product_data/train_product_data_rewrite.parquet\"\n",
    "image_folder = \"C:/Users//ReVision/data/product_data/product_images\"\n",
    "\n",
    "add_images_to_dataframe(input_tsv, valid_output, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tsv = \"C:/Users//ReVision/data/product_data/valid_product_data_rewrite.tsv\"\n",
    "valid_output = \"C:/Users//ReVision/data/product_data/valid_product_data_rewrite.parquet\"\n",
    "image_folder = \"C:/Users//ReVision/data/product_data/product_images\"\n",
    "\n",
    "add_images_to_dataframe(input_tsv, valid_output, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Parquet file back into a DataFrame\n",
    "df = pd.read_parquet('train_product_data_rewrite.parquet', engine='auto')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
